# Optimize TensorFlow Models for Deployment with TensorRT  

This repository contains my work from the **"Optimize TensorFlow Models for Deployment with TensorRT"** guided project on Coursera.  
The project focuses on accelerating TensorFlow models using **NVIDIA TensorRT** for high-performance AI deployment.  

---

## 📌 Project Overview  
In this project, I worked on:  
- Optimizing TensorFlow models with **NVIDIA TensorRT**  
- Leveraging **FP32, FP16, and INT8 precision** for performance gains  
- Fine-tuning TF-TRT parameters to boost inference speed and throughput  
- Preparing models for efficient, production-ready deployment  

---

## 🛠 Technologies Used  
- **TensorFlow**  
- **TensorRT**  
- **Python**  
- **CUDA Toolkit**  
- **Jupyter Notebook**  

---

## 🚀 Key Skills Gained  
- AI model optimization for speed and efficiency  
- Precision mode selection and benchmarking (FP32, FP16, INT8)  
- Performance profiling and inference tuning  
- Preparing deep learning models for production environments  

---

## 📂 Repository Structure  
- 📁 notebooks/ # Jupyter Notebooks with optimization steps
- 📁 models/ # Sample models for testing optimization
- 📁 benchmarks/ # Performance benchmarks and results
- README.md # Project documentation

---

## 📜 Certificate  
[View Coursera Certificate](#https://coursera.org/share/0ae4fa0395600c39e1430a9e92884dd4)  <!-- Replace # with the actual certificate link -->

---

## 🤝 Connect  
If you are working on AI deployment or model optimization, feel free to connect with me:  
[LinkedIn Profile](#https://www.linkedin.com/in/palaniappan-yeagappan/)
